"""
Interface principal do sistema usando Streamlit
Dashboard interativo para monitoramento em tempo real
"""

import queue
import tempfile
import threading
import time
from pathlib import Path
from typing import Any, Dict, Optional

import cv2
import numpy as np
import pandas as pd
import streamlit as st

# Configurar p√°gina
st.set_page_config(
    page_title="RIVAC-CV - Monitoramento por Vis√£o Computacional",
    page_icon="üë•",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Imports do sistema
try:
    from src.deteccao.yolo_detector import YOLODetector
    from src.ingestao.video_source import VideoSource
    from src.pipeline import DetectionPipeline
    from src.utils.config import load_config, save_config
    from src.utils.logger import get_logger
except ImportError as e:
    st.error(f"Erro ao importar m√≥dulos do sistema: {e}")
    st.stop()

# Configurar logger
logger = get_logger("streamlit_app")

# Configurar estilos CSS
st.markdown(
    """
<style>
    .main-header {
        background: linear-gradient(90deg, #1f77b4, #17becf);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    .status-running {
        color: #00ff00;
        font-weight: bold;
    }
    .status-stopped {
        color: #ff0000;
        font-weight: bold;
    }
</style>
""",
    unsafe_allow_html=True,
)


def get_available_videos():
    """Retorna lista de v√≠deos dispon√≠veis em data/videos/."""
    videos_dir = Path("data/videos")
    if not videos_dir.exists():
        return []

    video_extensions = [".mp4", ".avi", ".mov", ".mkv", ".m4v", ".flv", ".wmv"]
    available_videos = []

    for video_file in videos_dir.iterdir():
        if video_file.is_file() and video_file.suffix.lower() in video_extensions:
            # Obter informa√ß√µes do arquivo
            file_size = video_file.stat().st_size / (1024 * 1024)  # MB

            # Tentar obter informa√ß√µes do v√≠deo usando OpenCV
            video_info = {"duration": "N/A", "fps": "N/A", "resolution": "N/A"}
            try:
                cap = cv2.VideoCapture(str(video_file))
                if cap.isOpened():
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

                    if fps > 0:
                        duration = frame_count / fps
                        video_info["duration"] = f"{duration:.1f}s"
                        video_info["fps"] = f"{fps:.1f}"
                        video_info["resolution"] = f"{width}x{height}"
                cap.release()
            except:
                pass  # Se n√£o conseguir obter informa√ß√µes, usa valores padr√£o

            available_videos.append(
                {"name": video_file.name, "path": str(video_file), "size_mb": round(file_size, 1), **video_info}
            )

    return sorted(available_videos, key=lambda x: x["name"])


def initialize_session_state():
    """Inicializa estado da sess√£o."""
    if "pipeline" not in st.session_state:
        st.session_state.pipeline = None
    if "is_running" not in st.session_state:
        st.session_state.is_running = False
    if "config" not in st.session_state:
        st.session_state.config = load_config()
    if "detection_results" not in st.session_state:
        st.session_state.detection_results = []
    if "current_frame" not in st.session_state:
        st.session_state.current_frame = None
    if "statistics" not in st.session_state:
        st.session_state.statistics = {}
    if "frame_queue" not in st.session_state:
        st.session_state.frame_queue = queue.Queue(maxsize=10)
    if "results_queue" not in st.session_state:
        st.session_state.results_queue = queue.Queue(maxsize=100)
    if "video_finished" not in st.session_state:
        st.session_state.video_finished = False
    if "total_video_frames" not in st.session_state:
        st.session_state.total_video_frames = 0


def render_header():
    """Renderiza cabe√ßalho da aplica√ß√£o."""
    st.markdown(
        """
    <div class="main-header">
        <h1>RIVAC-CV - Sistema de Monitoramento por Vis√£o Computacional</h1>
        <p>An√°lise inteligente de fluxo de pessoas em ambientes de varejo</p>
    </div>
    """,
        unsafe_allow_html=True,
    )


def render_sidebar():
    """Renderiza barra lateral com configura√ß√µes."""
    st.sidebar.title("Configura√ß√µes")

    # Se√ß√£o de entrada de v√≠deo
    st.sidebar.header("Fonte de V√≠deo")

    source_type = st.sidebar.selectbox("Tipo de fonte:", ["Webcam", "Arquivo de v√≠deo", "URL/Stream", "C√¢mera IP"])

    source_path = None

    if source_type == "Webcam":
        camera_id = st.sidebar.number_input("ID da c√¢mera:", min_value=0, max_value=10, value=0)
        source_path = camera_id

    elif source_type == "Arquivo de v√≠deo":
        # Obter v√≠deos dispon√≠veis
        available_videos = get_available_videos()

        if available_videos:
            st.sidebar.subheader("V√≠deos Dispon√≠veis")

            # Criar op√ß√µes para selectbox
            video_options = ["Fazer upload de novo arquivo..."]
            for video in available_videos:
                video_options.append(f"{video['name']} ({video['size_mb']} MB)")

            selected_option = st.sidebar.selectbox("Escolher v√≠deo:", video_options)

            if selected_option != "Fazer upload de novo arquivo...":
                # Usu√°rio selecionou um v√≠deo existente
                video_name = selected_option.split(" (")[0]
                selected_video = next(v for v in available_videos if v["name"] == video_name)
                source_path = selected_video["path"]

                # Mostrar informa√ß√µes detalhadas do v√≠deo selecionado
                st.sidebar.success(f"V√≠deo selecionado: {video_name}")

                # Criar um expander com informa√ß√µes detalhadas
                with st.sidebar.expander("Informa√ß√µes do V√≠deo"):
                    st.write(f"**Arquivo:** {selected_video['name']}")
                    st.write(f"**Tamanho:** {selected_video['size_mb']} MB")
                    st.write(f"**Dura√ß√£o:** {selected_video['duration']}")
                    st.write(f"**FPS:** {selected_video['fps']}")
                    st.write(f"**Resolu√ß√£o:** {selected_video['resolution']}")

            else:
                # Usu√°rio quer fazer upload
                uploaded_file = st.sidebar.file_uploader(
                    "Fazer upload de arquivo:",
                    type=["mp4", "avi", "mov", "mkv"],
                    help="Formatos suportados: MP4, AVI, MOV, MKV",
                )
                if uploaded_file:
                    # Salvar arquivo tempor√°rio
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
                        tmp_file.write(uploaded_file.read())
                        source_path = tmp_file.name
                    st.sidebar.success(f"Upload conclu√≠do: {uploaded_file.name}")
        else:
            # Nenhum v√≠deo dispon√≠vel, apenas upload
            st.sidebar.info("Nenhum v√≠deo encontrado em data/videos/")
            uploaded_file = st.sidebar.file_uploader(
                "Fazer upload de arquivo:",
                type=["mp4", "avi", "mov", "mkv"],
                help="Formatos suportados: MP4, AVI, MOV, MKV",
            )
            if uploaded_file:
                # Salvar arquivo tempor√°rio
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    source_path = tmp_file.name
                st.sidebar.success(f"Upload conclu√≠do: {uploaded_file.name}")

    elif source_type == "URL/Stream":
        source_path = st.sidebar.text_input("URL do stream:")

    elif source_type == "C√¢mera IP":
        ip = st.sidebar.text_input("IP da c√¢mera:", value="192.168.1.100")
        port = st.sidebar.number_input("Porta:", value=8080)
        username = st.sidebar.text_input("Usu√°rio:")
        password = st.sidebar.text_input("Senha:", type="password")

        if ip and username and password:
            source_path = f"rtsp://{username}:{password}@{ip}:{port}/stream"

    # Configura√ß√µes de detec√ß√£o
    st.sidebar.header("Detec√ß√£o")

    model_options = {
        "YOLOv11n (R√°pido)": "data/models/yolo11n.pt",
        "YOLOv11s (Balanceado)": "data/models/yolo11s.pt",
        "YOLOv11m (Preciso)": "data/models/yolo11m.pt",
        "YOLOv11l (Muito Preciso)": "data/models/yolo11l.pt",
    }

    selected_model = st.sidebar.selectbox("Modelo:", list(model_options.keys()))
    model_path = model_options[selected_model]

    confidence = st.sidebar.slider("Confian√ßa m√≠nima:", min_value=0.1, max_value=1.0, value=0.3, step=0.05)

    iou_threshold = st.sidebar.slider("Threshold IoU:", min_value=0.1, max_value=1.0, value=0.5, step=0.05)

    # Configura√ß√µes de visualiza√ß√£o
    st.sidebar.header("Visualiza√ß√£o")

    show_bboxes = st.sidebar.checkbox("Mostrar bounding boxes", value=True)
    show_confidence = st.sidebar.checkbox("Mostrar confian√ßa", value=True)

    return {
        "source_path": source_path,
        "model_path": model_path,
        "confidence": confidence,
        "iou_threshold": iou_threshold,
        "show_bboxes": show_bboxes,
        "show_confidence": show_confidence,
    }


def setup_pipeline(config: Dict[str, Any]) -> bool:
    """Configura o pipeline de detec√ß√£o."""
    try:
        if not config["source_path"]:
            st.error("Por favor, configure uma fonte de v√≠deo.")
            return False

        # Criar pipeline
        pipeline = DetectionPipeline()

        # Configurar fonte
        if not pipeline.setup_source(config["source_path"]):
            st.error("Erro ao configurar fonte de v√≠deo.")
            return False

        # Obter informa√ß√µes do v√≠deo para detectar o fim
        try:
            if isinstance(config["source_path"], str) and Path(config["source_path"]).exists():
                cap = cv2.VideoCapture(config["source_path"])
                if cap.isOpened():
                    st.session_state.total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    cap.release()
                else:
                    st.session_state.total_video_frames = 0
            else:
                st.session_state.total_video_frames = 0  # Para streams/webcam
        except:
            st.session_state.total_video_frames = 0

        # Configurar detector
        detector_config = {
            "confidence": config["confidence"],
            "iou_threshold": config["iou_threshold"],
            "classes": [0],  # Apenas pessoas
            "device": "auto",
        }

        if not pipeline.setup_detector(config["model_path"], **detector_config):
            st.error("Erro ao configurar detector.")
            return False

        st.session_state.pipeline = pipeline
        st.session_state.video_finished = False
        return True

    except Exception as e:
        st.error(f"Erro ao configurar pipeline: {e}")
        logger.error(f"Erro na configura√ß√£o: {e}")
        return False


def create_frame_callback(frame_queue, results_queue, total_frames=0):
    """Cria callback que usa queues thread-safe."""

    def process_frame_callback(frame, detections, frame_number):
        """Callback chamado a cada frame processado."""
        # Usar queues thread-safe em vez de session_state diretamente
        frame_data = {
            "frame": frame.copy(),
            "detections": [det.to_dict() for det in detections],
            "frame_number": frame_number,
            "timestamp": time.time(),
            "detections_count": len(detections),
        }

        # Adicionar √† queue de frames (non-blocking, descarta se cheia)
        try:
            frame_queue.put_nowait(frame_data)
        except queue.Full:
            # Se a queue estiver cheia, remove o mais antigo e adiciona o novo
            try:
                frame_queue.get_nowait()
                frame_queue.put_nowait(frame_data)
            except queue.Empty:
                pass

        # Adicionar √† queue de resultados
        result_data = {
            "frame_number": frame_number,
            "timestamp": time.time(),
            "detections_count": len(detections),
            "detections": [det.to_dict() for det in detections],
        }

        try:
            results_queue.put_nowait(result_data)
        except queue.Full:
            # Se a queue estiver cheia, remove o mais antigo e adiciona o novo
            try:
                results_queue.get_nowait()
                results_queue.put_nowait(result_data)
            except queue.Empty:
                pass

        # Verificar se chegou ao fim do v√≠deo (para arquivos de v√≠deo)
        if total_frames > 0 and frame_number >= total_frames:
            try:
                results_queue.put_nowait({"video_finished": True})
            except queue.Full:
                pass

    return process_frame_callback


def process_queues():
    """Processa queues de frames e resultados de forma thread-safe."""
    # Processar queue de frames
    try:
        while not st.session_state.frame_queue.empty():
            frame_data = st.session_state.frame_queue.get_nowait()
            st.session_state.current_frame = frame_data["frame"]
    except queue.Empty:
        pass

    # Processar queue de resultados
    try:
        while not st.session_state.results_queue.empty():
            result_data = st.session_state.results_queue.get_nowait()

            # Verificar se √© uma mensagem de fim de v√≠deo
            if isinstance(result_data, dict) and result_data.get("video_finished"):
                st.session_state.video_finished = True
                if st.session_state.pipeline:
                    st.session_state.pipeline.stop()
                st.session_state.is_running = False
                continue

            # Dados normais de detec√ß√£o
            st.session_state.detection_results.append(result_data)

            # Manter apenas √∫ltimos 100 frames para economizar mem√≥ria
            if len(st.session_state.detection_results) > 100:
                st.session_state.detection_results.pop(0)
    except queue.Empty:
        pass


def draw_detections(frame: np.ndarray, detections: list, config: Dict[str, Any]) -> np.ndarray:
    """Desenha detec√ß√µes no frame."""
    if not config.get("show_bboxes", True):
        return frame

    annotated_frame = frame.copy()

    for detection in detections:
        try:
            x1, y1, x2, y2 = map(int, detection["bbox"])
            confidence = detection["confidence"]
            class_name = detection.get("class_name", "object")

            # Garantir que class_name seja uma string
            if not isinstance(class_name, str):
                class_name = str(class_name) if class_name is not None else "object"

            # Desenhar bounding box
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # Desenhar label
            if config.get("show_confidence", True):
                label = f"{class_name}: {confidence:.2f}"
            else:
                label = class_name

            # Garantir que label seja uma string v√°lida
            label = str(label) if label is not None else "unknown"

            # Calcular posi√ß√£o do texto
            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(annotated_frame, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 255, 0), -1)
            cv2.putText(annotated_frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

        except Exception as e:
            # Se houver erro em uma detec√ß√£o espec√≠fica, continue com as outras
            logger.warning(f"Erro ao desenhar detec√ß√£o: {e}")
            continue

    return annotated_frame


def render_main_content():
    """Renderiza conte√∫do principal."""
    config = render_sidebar()

    # √Årea principal dividida em colunas
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("Monitor de V√≠deo")

        # Container para o v√≠deo
        video_container = st.empty()

        # Controles
        control_col1, control_col2, control_col3 = st.columns(3)

        with control_col1:
            if st.button("Iniciar", type="primary"):
                if setup_pipeline(config):
                    st.session_state.is_running = True

                    # Criar callback thread-safe
                    frame_callback = create_frame_callback(
                        st.session_state.frame_queue,
                        st.session_state.results_queue,
                        st.session_state.total_video_frames,
                    )
                    st.session_state.pipeline.add_frame_callback(frame_callback)

                    # Salvar refer√™ncia do pipeline para evitar problemas de thread
                    pipeline_instance = st.session_state.pipeline

                    # Executar pipeline em thread separada
                    def run_pipeline():
                        try:
                            results = pipeline_instance.run(max_frames=None, show_progress=False)
                            # Salvar resultados em vari√°vel global tempor√°ria
                            st.session_state._temp_results = results
                            st.session_state._temp_execution_finished = True
                        except Exception as e:
                            logger.error(f"Erro na execu√ß√£o: {e}")
                            st.session_state._temp_error = str(e)
                            st.session_state._temp_execution_finished = True

                    # Inicializar flags tempor√°rias
                    st.session_state._temp_execution_finished = False
                    st.session_state._temp_results = None
                    st.session_state._temp_error = None

                    thread = threading.Thread(target=run_pipeline, daemon=True)
                    thread.start()

                    st.success("Processamento iniciado!")

        with control_col2:
            if st.button("Parar"):
                if st.session_state.pipeline:
                    st.session_state.pipeline.stop()
                st.session_state.is_running = False
                st.info("Processamento parado.")

        with control_col3:
            if st.button("Exportar Dados"):
                if st.session_state.detection_results:
                    # Preparar dados para download
                    df = pd.DataFrame()
                    for frame_result in st.session_state.detection_results:
                        for detection in frame_result["detections"]:
                            row = detection.copy()
                            row["frame_number"] = frame_result["frame_number"]
                            row["timestamp"] = frame_result["timestamp"]
                            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)

                    csv = df.to_csv(index=False)
                    st.download_button(
                        label="Download CSV",
                        data=csv,
                        file_name=f"detections_{int(time.time())}.csv",
                        mime="text/csv",
                    )

        # Mostrar frame atual
        if st.session_state.current_frame is not None:
            # Obter √∫ltimas detec√ß√µes
            latest_detections = []
            if st.session_state.detection_results and len(st.session_state.detection_results) > 0:
                last_result = st.session_state.detection_results[-1]
                if isinstance(last_result, dict) and "detections" in last_result:
                    latest_detections = last_result["detections"]
                    # Garantir que latest_detections √© uma lista
                    if not isinstance(latest_detections, list):
                        latest_detections = []

            # Desenhar detec√ß√µes
            try:
                annotated_frame = draw_detections(st.session_state.current_frame, latest_detections, config)
            except Exception as e:
                logger.warning(f"Erro ao desenhar detec√ß√µes: {e}")
                annotated_frame = st.session_state.current_frame

            # Mostrar no Streamlit
            video_container.image(
                cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True
            )

        # Mostrar barra de progresso para arquivos de v√≠deo
        if st.session_state.is_running and st.session_state.total_video_frames > 0:
            current_frame = 0
            if st.session_state.detection_results:
                current_frame = st.session_state.detection_results[-1]["frame_number"]

            progress = min(current_frame / st.session_state.total_video_frames, 1.0)
            st.progress(
                progress,
                text=f"Progresso: {progress*100:.1f}% ({current_frame}/{st.session_state.total_video_frames} frames)",
            )

    with col2:
        st.header("Estat√≠sticas")

        # Status do sistema
        if st.session_state.is_running:
            st.markdown('<p class="status-running">üü¢ EXECUTANDO</p>', unsafe_allow_html=True)
        else:
            st.markdown('<p class="status-stopped">üî¥ PARADO</p>', unsafe_allow_html=True)

        # M√©tricas em tempo real
        if st.session_state.detection_results:
            latest_frame = st.session_state.detection_results[-1]

            st.metric("Pessoas Detectadas", latest_frame["detections_count"])
            st.metric("Frame Atual", latest_frame["frame_number"])

            if st.session_state.pipeline:
                stats = st.session_state.pipeline.get_statistics()
                st.metric("FPS M√©dio", f"{stats.get('average_fps', 0):.1f}")
                st.metric("Total de Detec√ß√µes", stats.get("total_detections", 0))

        # Gr√°fico de detec√ß√µes por frame
        if len(st.session_state.detection_results) > 1:
            st.subheader("Detec√ß√µes por Frame")

            df_chart = pd.DataFrame(
                [
                    {"frame": r["frame_number"], "detections": r["detections_count"]}
                    for r in st.session_state.detection_results[-50:]  # √öltimos 50 frames
                ]
            )

            st.line_chart(df_chart.set_index("frame"))

        # Hist√≥rico de detec√ß√µes
        st.subheader("Hist√≥rico Recente")
        if st.session_state.detection_results:
            for result in st.session_state.detection_results[-10:]:  # √öltimos 10
                timestamp = time.strftime("%H:%M:%S", time.localtime(result["timestamp"]))
                st.write(f">{timestamp} - Frame {result['frame_number']}: {result['detections_count']} pessoas")


def main():
    """Fun√ß√£o principal da aplica√ß√£o."""
    initialize_session_state()
    render_header()

    # Processar queues de dados vindos das threads
    process_queues()

    render_main_content()

    # Verificar se a execu√ß√£o da thread terminou ou se o v√≠deo acabou
    if hasattr(st.session_state, "_temp_execution_finished") and st.session_state._temp_execution_finished:
        # Processar resultados da thread
        if st.session_state._temp_results:
            st.session_state.statistics = st.session_state._temp_results
            st.success("Processamento conclu√≠do!")
        elif st.session_state._temp_error:
            st.error(f"Erro durante processamento: {st.session_state._temp_error}")

        # Limpar flags tempor√°rias
        st.session_state._temp_execution_finished = False
        st.session_state._temp_results = None
        st.session_state._temp_error = None
        st.session_state.is_running = False

    # Verificar se o v√≠deo terminou
    if st.session_state.video_finished and st.session_state.is_running:
        st.session_state.is_running = False
        st.success("V√≠deo processado completamente!")

        # Mostrar estat√≠sticas finais
        if st.session_state.detection_results:
            total_detections = sum(r["detections_count"] for r in st.session_state.detection_results)
            total_frames = len(st.session_state.detection_results)
            avg_detections = total_detections / max(total_frames, 1)

            st.info(
                f"**Estat√≠sticas Finais:**\n"
                f"- Total de frames processados: {total_frames}\n"
                f"- Total de detec√ß√µes: {total_detections}\n"
                f"- M√©dia de detec√ß√µes por frame: {avg_detections:.2f}"
            )

    # Auto-refresh para atualizar interface
    if st.session_state.is_running:
        time.sleep(0.1)
        st.rerun()


if __name__ == "__main__":
    main()
