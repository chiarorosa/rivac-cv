"""
Interface principal do sistema usando Streamlit
Dashboard interativo para monitoramento em tempo real
"""

import tempfile
import threading
import time
from pathlib import Path
from typing import Any, Dict, Optional

import cv2
import numpy as np
import pandas as pd
import streamlit as st

# Configurar p√°gina
st.set_page_config(
    page_title="RIVAC-CV - Monitoramento por Vis√£o Computacional",
    page_icon="üë•",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Imports do sistema
try:
    from src.deteccao.yolo_detector import YOLODetector
    from src.ingestao.video_source import VideoSource
    from src.pipeline import DetectionPipeline
    from src.utils.config import load_config, save_config
    from src.utils.logger import get_logger
except ImportError as e:
    st.error(f"Erro ao importar m√≥dulos do sistema: {e}")
    st.stop()

# Configurar logger
logger = get_logger("streamlit_app")

# Configurar estilos CSS
st.markdown(
    """
<style>
    .main-header {
        background: linear-gradient(90deg, #1f77b4, #17becf);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    .status-running {
        color: #00ff00;
        font-weight: bold;
    }
    .status-stopped {
        color: #ff0000;
        font-weight: bold;
    }
</style>
""",
    unsafe_allow_html=True,
)


def get_available_videos():
    """Retorna lista de v√≠deos dispon√≠veis em data/videos/."""
    videos_dir = Path("data/videos")
    if not videos_dir.exists():
        return []
    
    video_extensions = [".mp4", ".avi", ".mov", ".mkv", ".m4v", ".flv", ".wmv"]
    available_videos = []
    
    for video_file in videos_dir.iterdir():
        if video_file.is_file() and video_file.suffix.lower() in video_extensions:
            # Obter informa√ß√µes do arquivo
            file_size = video_file.stat().st_size / (1024 * 1024)  # MB
            
            # Tentar obter informa√ß√µes do v√≠deo usando OpenCV
            video_info = {"duration": "N/A", "fps": "N/A", "resolution": "N/A"}
            try:
                cap = cv2.VideoCapture(str(video_file))
                if cap.isOpened():
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    
                    if fps > 0:
                        duration = frame_count / fps
                        video_info["duration"] = f"{duration:.1f}s"
                        video_info["fps"] = f"{fps:.1f}"
                        video_info["resolution"] = f"{width}x{height}"
                cap.release()
            except:
                pass  # Se n√£o conseguir obter informa√ß√µes, usa valores padr√£o
            
            available_videos.append({
                "name": video_file.name,
                "path": str(video_file),
                "size_mb": round(file_size, 1),
                **video_info
            })
    
    return sorted(available_videos, key=lambda x: x["name"])


def initialize_session_state():
    """Inicializa estado da sess√£o."""
    if "pipeline" not in st.session_state:
        st.session_state.pipeline = None
    if "is_running" not in st.session_state:
        st.session_state.is_running = False
    if "config" not in st.session_state:
        st.session_state.config = load_config()
    if "detection_results" not in st.session_state:
        st.session_state.detection_results = []
    if "current_frame" not in st.session_state:
        st.session_state.current_frame = None
    if "statistics" not in st.session_state:
        st.session_state.statistics = {}


def render_header():
    """Renderiza cabe√ßalho da aplica√ß√£o."""
    st.markdown(
        """
    <div class="main-header">
        <h1>üõí RIVAC-CV - Sistema de Monitoramento por Vis√£o Computacional</h1>
        <p>An√°lise inteligente de fluxo de pessoas em ambientes de varejo</p>
    </div>
    """,
        unsafe_allow_html=True,
    )


def render_sidebar():
    """Renderiza barra lateral com configura√ß√µes."""
    st.sidebar.title("‚öôÔ∏è Configura√ß√µes")

    # Se√ß√£o de entrada de v√≠deo
    st.sidebar.header("üìπ Fonte de V√≠deo")

    source_type = st.sidebar.selectbox("Tipo de fonte:", ["Webcam", "Arquivo de v√≠deo", "URL/Stream", "C√¢mera IP"])

    source_path = None

    if source_type == "Webcam":
        camera_id = st.sidebar.number_input("ID da c√¢mera:", min_value=0, max_value=10, value=0)
        source_path = camera_id

    elif source_type == "Arquivo de v√≠deo":
        # Obter v√≠deos dispon√≠veis
        available_videos = get_available_videos()
        
        if available_videos:
            st.sidebar.subheader("üìã V√≠deos Dispon√≠veis")
            
            # Criar op√ß√µes para selectbox
            video_options = ["üÜï Fazer upload de novo arquivo..."]
            for video in available_videos:
                video_options.append(f"üìΩÔ∏è {video['name']} ({video['size_mb']} MB)")
            
            selected_option = st.sidebar.selectbox("Escolher v√≠deo:", video_options)
            
            if selected_option.startswith("üìΩÔ∏è"):
                # Usu√°rio selecionou um v√≠deo existente
                video_name = selected_option.split("üìΩÔ∏è ")[1].split(" (")[0]
                selected_video = next(v for v in available_videos if v["name"] == video_name)
                source_path = selected_video["path"]
                
                # Mostrar informa√ß√µes detalhadas do v√≠deo selecionado
                st.sidebar.success(f"‚úÖ V√≠deo selecionado: {video_name}")
                
                # Criar um expander com informa√ß√µes detalhadas
                with st.sidebar.expander("‚ÑπÔ∏è Informa√ß√µes do V√≠deo"):
                    st.write(f"**üìÅ Arquivo:** {selected_video['name']}")
                    st.write(f"**üìè Tamanho:** {selected_video['size_mb']} MB")
                    st.write(f"**‚è±Ô∏è Dura√ß√£o:** {selected_video['duration']}")
                    st.write(f"**üé¨ FPS:** {selected_video['fps']}")
                    st.write(f"**üì∫ Resolu√ß√£o:** {selected_video['resolution']}")
                
            else:
                # Usu√°rio quer fazer upload
                uploaded_file = st.sidebar.file_uploader(
                    "Fazer upload de arquivo:", 
                    type=["mp4", "avi", "mov", "mkv"],
                    help="Formatos suportados: MP4, AVI, MOV, MKV"
                )
                if uploaded_file:
                    # Salvar arquivo tempor√°rio
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
                        tmp_file.write(uploaded_file.read())
                        source_path = tmp_file.name
                    st.sidebar.success(f"‚úÖ Upload conclu√≠do: {uploaded_file.name}")
        else:
            # Nenhum v√≠deo dispon√≠vel, apenas upload
            st.sidebar.info("‚ÑπÔ∏è Nenhum v√≠deo encontrado em data/videos/")
            uploaded_file = st.sidebar.file_uploader(
                "Fazer upload de arquivo:", 
                type=["mp4", "avi", "mov", "mkv"],
                help="Formatos suportados: MP4, AVI, MOV, MKV"
            )
            if uploaded_file:
                # Salvar arquivo tempor√°rio
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    source_path = tmp_file.name
                st.sidebar.success(f"‚úÖ Upload conclu√≠do: {uploaded_file.name}")

    elif source_type == "URL/Stream":
        source_path = st.sidebar.text_input("URL do stream:")

    elif source_type == "C√¢mera IP":
        ip = st.sidebar.text_input("IP da c√¢mera:", value="192.168.1.100")
        port = st.sidebar.number_input("Porta:", value=8080)
        username = st.sidebar.text_input("Usu√°rio:")
        password = st.sidebar.text_input("Senha:", type="password")

        if ip and username and password:
            source_path = f"rtsp://{username}:{password}@{ip}:{port}/stream"

    # Configura√ß√µes de detec√ß√£o
    st.sidebar.header("üîç Detec√ß√£o")

    model_options = {
        "YOLOv11n (R√°pido)": "data/models/yolo11n.pt",
        "YOLOv11s (Balanceado)": "data/models/yolo11s.pt",
        "YOLOv11m (Preciso)": "data/models/yolo11m.pt",
        "YOLOv11l (Muito Preciso)": "data/models/yolo11l.pt",
    }

    selected_model = st.sidebar.selectbox("Modelo:", list(model_options.keys()))
    model_path = model_options[selected_model]

    confidence = st.sidebar.slider("Confian√ßa m√≠nima:", min_value=0.1, max_value=1.0, value=0.3, step=0.05)

    iou_threshold = st.sidebar.slider("Threshold IoU:", min_value=0.1, max_value=1.0, value=0.5, step=0.05)

    # Configura√ß√µes de visualiza√ß√£o
    st.sidebar.header("üëÅÔ∏è Visualiza√ß√£o")

    show_bboxes = st.sidebar.checkbox("Mostrar bounding boxes", value=True)
    show_confidence = st.sidebar.checkbox("Mostrar confian√ßa", value=True)
    show_fps = st.sidebar.checkbox("Mostrar FPS", value=True)

    return {
        "source_path": source_path,
        "model_path": model_path,
        "confidence": confidence,
        "iou_threshold": iou_threshold,
        "show_bboxes": show_bboxes,
        "show_confidence": show_confidence,
        "show_fps": show_fps,
    }


def setup_pipeline(config: Dict[str, Any]) -> bool:
    """Configura o pipeline de detec√ß√£o."""
    try:
        if not config["source_path"]:
            st.error("‚ö†Ô∏è Por favor, configure uma fonte de v√≠deo.")
            return False

        # Criar pipeline
        pipeline = DetectionPipeline()

        # Configurar fonte
        if not pipeline.setup_source(config["source_path"]):
            st.error("‚ùå Erro ao configurar fonte de v√≠deo.")
            return False

        # Configurar detector
        detector_config = {
            "confidence": config["confidence"],
            "iou_threshold": config["iou_threshold"],
            "classes": [0],  # Apenas pessoas
            "device": "auto",
        }

        if not pipeline.setup_detector(config["model_path"], **detector_config):
            st.error("‚ùå Erro ao configurar detector.")
            return False

        st.session_state.pipeline = pipeline
        return True

    except Exception as e:
        st.error(f"‚ùå Erro ao configurar pipeline: {e}")
        logger.error(f"Erro na configura√ß√£o: {e}")
        return False


def process_frame_callback(frame, detections, frame_number):
    """Callback chamado a cada frame processado."""
    # Atualizar frame atual
    st.session_state.current_frame = frame.copy()

    # Adicionar detec√ß√µes aos resultados
    frame_results = {
        "frame_number": frame_number,
        "timestamp": time.time(),
        "detections_count": len(detections),
        "detections": [det.to_dict() for det in detections],
    }
    st.session_state.detection_results.append(frame_results)

    # Manter apenas √∫ltimos 100 frames para economizar mem√≥ria
    if len(st.session_state.detection_results) > 100:
        st.session_state.detection_results.pop(0)


def draw_detections(frame: np.ndarray, detections: list, config: Dict[str, Any]) -> np.ndarray:
    """Desenha detec√ß√µes no frame."""
    if not config.get("show_bboxes", True):
        return frame

    annotated_frame = frame.copy()

    for detection in detections:
        x1, y1, x2, y2 = map(int, detection["bbox"])
        confidence = detection["confidence"]
        class_name = detection.get("class_name", "object")

        # Desenhar bounding box
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # Desenhar label
        if config.get("show_confidence", True):
            label = f"{class_name}: {confidence:.2f}"
        else:
            label = class_name

        # Calcular posi√ß√£o do texto
        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
        cv2.rectangle(annotated_frame, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 255, 0), -1)
        cv2.putText(annotated_frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

    return annotated_frame


def render_main_content():
    """Renderiza conte√∫do principal."""
    config = render_sidebar()

    # √Årea principal dividida em colunas
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("üì∫ Monitor de V√≠deo")

        # Container para o v√≠deo
        video_container = st.empty()

        # Controles
        control_col1, control_col2, control_col3 = st.columns(3)

        with control_col1:
            if st.button("‚ñ∂Ô∏è Iniciar", type="primary"):
                if setup_pipeline(config):
                    st.session_state.is_running = True

                    # Adicionar callback
                    st.session_state.pipeline.add_frame_callback(process_frame_callback)

                    # Executar pipeline em thread separada
                    def run_pipeline():
                        try:
                            results = st.session_state.pipeline.run(max_frames=None, show_progress=False)
                            st.session_state.statistics = results
                        except Exception as e:
                            logger.error(f"Erro na execu√ß√£o: {e}")
                        finally:
                            st.session_state.is_running = False

                    thread = threading.Thread(target=run_pipeline, daemon=True)
                    thread.start()

                    st.success("‚úÖ Processamento iniciado!")

        with control_col2:
            if st.button("‚è∏Ô∏è Parar"):
                if st.session_state.pipeline:
                    st.session_state.pipeline.stop()
                st.session_state.is_running = False
                st.info("‚è∏Ô∏è Processamento parado.")

        with control_col3:
            if st.button("üíæ Exportar Dados"):
                if st.session_state.detection_results:
                    # Preparar dados para download
                    df = pd.DataFrame()
                    for frame_result in st.session_state.detection_results:
                        for detection in frame_result["detections"]:
                            row = detection.copy()
                            row["frame_number"] = frame_result["frame_number"]
                            row["timestamp"] = frame_result["timestamp"]
                            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)

                    csv = df.to_csv(index=False)
                    st.download_button(
                        label="üì• Download CSV",
                        data=csv,
                        file_name=f"detections_{int(time.time())}.csv",
                        mime="text/csv",
                    )

        # Mostrar frame atual
        if st.session_state.current_frame is not None:
            # Obter √∫ltimas detec√ß√µes
            latest_detections = []
            if st.session_state.detection_results:
                latest_detections = st.session_state.detection_results[-1]["detections"]

            # Desenhar detec√ß√µes
            annotated_frame = draw_detections(st.session_state.current_frame, latest_detections, config)

            # Mostrar no Streamlit
            video_container.image(
                cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_column_width=True
            )

    with col2:
        st.header("üìä Estat√≠sticas")

        # Status do sistema
        if st.session_state.is_running:
            st.markdown('<p class="status-running">üü¢ EXECUTANDO</p>', unsafe_allow_html=True)
        else:
            st.markdown('<p class="status-stopped">üî¥ PARADO</p>', unsafe_allow_html=True)

        # M√©tricas em tempo real
        if st.session_state.detection_results:
            latest_frame = st.session_state.detection_results[-1]

            st.metric("Pessoas Detectadas", latest_frame["detections_count"])
            st.metric("Frame Atual", latest_frame["frame_number"])

            if st.session_state.pipeline:
                stats = st.session_state.pipeline.get_statistics()
                st.metric("FPS M√©dio", f"{stats.get('average_fps', 0):.1f}")
                st.metric("Total de Detec√ß√µes", stats.get("total_detections", 0))

        # Gr√°fico de detec√ß√µes por frame
        if len(st.session_state.detection_results) > 1:
            st.subheader("üìà Detec√ß√µes por Frame")

            df_chart = pd.DataFrame(
                [
                    {"frame": r["frame_number"], "detections": r["detections_count"]}
                    for r in st.session_state.detection_results[-50:]  # √öltimos 50 frames
                ]
            )

            st.line_chart(df_chart.set_index("frame"))

        # Hist√≥rico de detec√ß√µes
        st.subheader("üìã Hist√≥rico Recente")
        if st.session_state.detection_results:
            for result in st.session_state.detection_results[-10:]:  # √öltimos 10
                timestamp = time.strftime("%H:%M:%S", time.localtime(result["timestamp"]))
                st.write(f"‚è∞ {timestamp} - Frame {result['frame_number']}: {result['detections_count']} pessoas")


def main():
    """Fun√ß√£o principal da aplica√ß√£o."""
    initialize_session_state()
    render_header()
    render_main_content()

    # Auto-refresh para atualizar interface
    if st.session_state.is_running:
        time.sleep(0.1)
        st.rerun()


if __name__ == "__main__":
    main()
